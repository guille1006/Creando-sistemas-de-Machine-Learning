{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "db4a88f2",
   "metadata": {},
   "source": [
    "Este primer capitulo se centrará en explicar los aspectos básicos detras del uso del Machine Learning\n",
    "\n",
    "## Cuando usar ML\n",
    "Como sabemos, los algorítmos de ML no son una herramienta mágica capaz de resolver todos los problemas de la misma manera, incluso en problemas que pueden ser solucionados con ML, es posible que este proceso no sea el más óptimo\n",
    "\n",
    "\n",
    "<div style=\"border: 10px solid black; padding: 10px;diplay: inline-block; margin:20px 0; width:fit-content;\">\n",
    "    Machine learning is an approach to (1)learn (2)complex patterns from (3)existing data and use these patterns to make (4)predictions on (5)unseen data.\n",
    "</div>\n",
    "\n",
    "1. Learn. el sistema es capaz de aprender.\n",
    "2. Complex patterns. Las soluciones con ML solo son posible si existe un patrón desde donde aprender, si nosotros tiramos un dado (juega únicamente el azar, no hay patrón), ML no sería capaz de predecir el siguiente resultado. \n",
    "3. Existing data. Como los ML aprenden de los datos, por lo que esto será la base de donde empezarán a aprender. Si los datos son malos o no son suficientes, nuestro sistema tendrá errores. \n",
    "4. Predictions. El fin que tiene nuestro programa es darnos una predicción. \n",
    "5. Unseen data. Son los datos donde queremos predecir su variable dependiente, es importante indicar que los datos no vistos deberán compartir los patrones que los datos con los que se ha entrenado el modelo. \n",
    "\n",
    "Debido a como aprender los ML actualmente, nuestro proyecto podrá brillar si además cumplen las siguientes caracteristicas:\n",
    "6. Es repetitivo. \n",
    "7. El coste de predicciones erroneas es barato.\n",
    "8. Es escalable. \n",
    "9. Puede haber patrones que cambien constantemente. Este aspecto puede diferir mucho del punto 5, pero ten en cuenta que nosotros querremos entender los patrones que cambian en tareas como en detectores de span de mail(ahora un spam puede venir del principe de arabia, pero mañana podría ser de Fernando Alonso), si nosotros intentasemos hardcodearlo, tendriamos que estar escribiendolo constantemente. \n",
    "\n",
    "## ML in research VS in production\n",
    "| Aspecto | Investigación | Producción |\n",
    "|-------|--------------|------------|\n",
    "| Objetivo principal | Rendimiento de modelos de última generación en conjuntos de datos de referencia (benchmarks) | Cumplir requisitos del mundo real y del negocio |\n",
    "| Requisitos | Enfoque principalmente académico | Diferentes partes interesadas tienen distintos requisitos |\n",
    "| Prioridad computacional | Entrenamiento rápido y alto rendimiento experimental | Inferencia rápida, baja latencia |\n",
    "| Datos | Estáticos | Cambian constantemente |\n",
    "| Equidad (Fairness) | A menudo no es una prioridad | Debe ser considerada |\n",
    "| Interpretabilidad | A menudo no es una prioridad | Debe ser considerada |\n",
    "\n",
    "\n",
    "## Objetivos del ML y el trabajo\n",
    "Primero deberemos considerar los objetivos del proyecto de ML propuesto. \n",
    "\n",
    "Cuando los data scientist se enfocan en las métricas de rendimineto, latencia, precisión... Las compañias no se fijan en estas métricas tan bonitas, según el economista Milton Friedman, su objetivo es maximizar el benecifico de los accionistas. Esto significa que buscan incrementar los beneficios, ya sea directamente o indirectamente: incrementando las ventas, reduciendo gastos, mayor satisfacción del cliente, más tiempo en gastado en la página web\n",
    "\n",
    "## Requerimientos para los sistemas ML\n",
    "No podemos decir que hemos diseñado satisfactoriamente un sistema de ML sin saber que requerimentos el sistema debe satisfacer, estos sistemas deberan tener: \n",
    "\n",
    "### Reliability / Fiabilidad\n",
    "El sistema deberá poder desempeñar su función correctamente a un alto nivel incluso en escenarios adversos (fallos en el hardware/software o errores humanos).\n",
    "\n",
    "Uno de los temas de la fiabilidad es como saber si un sistema está fallando. Los ML no son capaces de avisarte si están fallando, ellos simplemente te devolverán el resultado más probable que hayan calculado. \n",
    "\n",
    "### Scalability /  Escalabilidad\n",
    "Nuestro sistema de ML deberá ser capaz de escalar sus recursos, ya sea un *up-scaling* (exapndir recursos) o *down-scaling* (reducir recursos cuando no se neceisten). Esta caracteristica es muy importante a la hora de entender los momentos picos del sistema. \n",
    "\n",
    "### Maintainability / Mantenibilidad\n",
    "Consiste es en estructurar correctamente las cargas de trabajo y crear una infraestructura donde todos los contribudores puedan acceder. Algunos ejemplos son: \n",
    "* Documentar el código.\n",
    "* Código, datos y artefactos deberán estar versionados. \n",
    "* Los modelos deberán ser facilmente reproducibles.\n",
    "* Cuando un problema ocurra, varias personas podrán trabajar en solucionarlo.\n",
    "\n",
    "### Adaptability / Adaptabilidad\n",
    "Adaptarse al cambio de las distribuciones de datos y requisitos de negocios. El sistema debera ser capaz de descubrir aspectos para mejorar el desempeño y permitir actualizaciones sin que se caiga el servicio. Esto está muy relacionado con la **Mantenibilidad**\n",
    "\n",
    "\n",
    "## Función Objetivo --> Loss function\n",
    "Todos los modelos de ML necesitan una función objetivo que sirva para guiar el proceso de aprendizaje. Es también llamada *loss function* porque el objetivo de esta función es minimizar (u optimizar) la **pérdida** causada por las predicciones erroneas. Esta pérdida puede ser calculada mediante la comparación de las salidas dadas por el modelo con las etiquetas reales. \n",
    "\n",
    "### Desaparejar objetivos. \n",
    "Imagina que tienes que hacer un sistema en el cual tienes varios objetivos, y además, dos de ellos están enfrentados (esto significa que la disminución en pérdida en uno, conlleva un aumento en la pérdida del otro objetivo) lo que deberás hacer es crear una función que englobe ambas pérdidas:\n",
    "$$\n",
    "loss = \\alpha loss_1 + \\beta loss_2\n",
    "$$\n",
    "Con la función de pérdida anterior podrás manejar cuanta importancia le darás a cada una de las pérdidas, creando así una función donde su objetivo será minimizar el valor de la pérdida de ese sumatorio. La parte negativa de esta nueva función es que cada vez que querramos cambiar el valor de $\\alpha$ o $\\beta$ deberemos volver a entrenar todo el modelo. \n",
    "\n",
    "Otra forma de tratar con este problema es entrenar dos modelos donde cada uno optimize una función de pérdida, y que al final combinemos las salidas de ambos modelos, para así tunear tanto $\\alpha$ como $\\beta$ sin que haga falta volver a entrenar.\n",
    "$$\n",
    "\\alpha loss_1 + \\beta loss_2\n",
    "$$\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce719065",
   "metadata": {},
   "source": [
    "# Fundamentos de la Ingeniería de datos\n",
    "## Datos \n",
    "Prácticamente el elemento más importante a la hora de entrenar un modelo son los propios **datos**. Y esto lo saben las compañías, ya que se interesan más en manejar y en mejorar los datos que en mejorar el algorítmo. \n",
    "\n",
    "Pero hay que tener en cuenta que aunque gran parte del progreso en Deep Learning en las últimas decadas es gracias a las grandes cantidades de datos, más datos no implican mejor desempeño del modelo. Datos de mala calidad, como datos desactualizados o con etiquetas incorrectas pueden dañar este desempeño.\n",
    "\n",
    "## Fuentes de datos \n",
    "* Input data. Datos explicitemente introducidos por el usuario. Hay que tener cuidado con estos datos porque si de la más remota manera el usuario\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
